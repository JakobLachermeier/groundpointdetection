{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63c3b0a",
   "metadata": {},
   "source": [
    "# Dynamic Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d48b0f",
   "metadata": {},
   "source": [
    "## Setup Sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb4cf0",
   "metadata": {},
   "source": [
    "### basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a311d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "world  = client.get_world()\n",
    "bp_lib = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b4f17d",
   "metadata": {},
   "source": [
    "#### crossings location (default map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f466b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectator = world.get_spectator() \n",
    "#Intersection1 (checkerboard)\n",
    "inter1tv = carla.Transform(\n",
    "    carla.Location(\n",
    "        x=-45,\n",
    "        y=20,\n",
    "        z=60\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch=-90,\n",
    "        yaw=0,\n",
    "        roll=0\n",
    "    )\n",
    ")\n",
    "\n",
    "inter1pv1 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x=-60,\n",
    "        y=40,\n",
    "        z=7\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch=-30,\n",
    "        yaw=-60,\n",
    "        roll=0\n",
    "    )\n",
    ")\n",
    "\n",
    "inter1pv2 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x=-60,\n",
    "        y=20,\n",
    "        z=7.3\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch=-28,\n",
    "        yaw=33.5,\n",
    "        roll=0\n",
    "    )\n",
    ")\n",
    "\n",
    "inter1pv3 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x = -63.7,\n",
    "        y = 7.9,\n",
    "        z = 4.5\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch = -32,\n",
    "        yaw = 41.8,\n",
    "        roll = 0\n",
    "    )\n",
    ")\n",
    "\n",
    "inter1pv4 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x = -35.9,\n",
    "        y = 7.1,\n",
    "        z = 6.68\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch = -35,\n",
    "        yaw = 127,\n",
    "        roll = 0\n",
    "    )\n",
    ")\n",
    "\n",
    "inter1pv5 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x = -32,\n",
    "        y = 32.5,\n",
    "        z = 3.5\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch = -23,\n",
    "        yaw = -103,\n",
    "        roll = 0\n",
    "    )\n",
    ")\n",
    "\n",
    "inter1pv6 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x = -64.2,\n",
    "        y = 7.7,\n",
    "        z = 5\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch = -27,\n",
    "        yaw = 40,\n",
    "        roll = 0\n",
    "    )\n",
    ")\n",
    "\n",
    "#Intersection2 (museum)\n",
    "inter2tv = carla.Transform(\n",
    "    carla.Location(\n",
    "        x=90,\n",
    "        y=20,\n",
    "        z=60\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch=-90,\n",
    "        yaw=0,\n",
    "        roll=0\n",
    "    )\n",
    ")\n",
    "inter2pv1 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x=115,\n",
    "        y=40,\n",
    "        z=8.5\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch=-14,\n",
    "        yaw=-124,\n",
    "        roll=0\n",
    "    )\n",
    ")\n",
    "inter2pv2 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x = 96,\n",
    "        y = 46,\n",
    "        z = 7.9\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch = -29,\n",
    "        yaw = -72,\n",
    "        roll = 0\n",
    "    )\n",
    ")\n",
    "inter2pv3 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x = 92.29,\n",
    "        y = 3.84,\n",
    "        z = 5.2\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch = -8.8,\n",
    "        yaw = 73.2,\n",
    "        roll = 0\n",
    "    )\n",
    ")\n",
    "inter2pv4 = carla.Transform(\n",
    "    carla.Location(\n",
    "        x = 114.54,\n",
    "        y = -8.95,\n",
    "        z = 6.9\n",
    "    ),\n",
    "    carla.Rotation(\n",
    "        pitch = -25.81,\n",
    "        yaw = 124.43,\n",
    "        roll = 0\n",
    "    )\n",
    ")\n",
    "\n",
    "spectator.set_transform(inter1tv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed17a6ce",
   "metadata": {},
   "source": [
    "### parameters and spawning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "792dcbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Camera Parameters\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', '1920')\n",
    "camera_bp.set_attribute('image_size_y', '1080')\n",
    "\n",
    "camera_bp_seg = bp_lib.find('sensor.camera.instance_segmentation')\n",
    "camera_bp_seg.set_attribute('image_size_x', '1920')\n",
    "camera_bp_seg.set_attribute('image_size_y', '1080')\n",
    "\n",
    "## set view\n",
    "c_pv_spawn_location = inter1pv1\n",
    "c_tv_spawn_location = inter1tv\n",
    "\n",
    "# Create a queue to store and retrieve the sensor data\n",
    "camera_pv = world.spawn_actor(camera_bp, c_pv_spawn_location)\n",
    "camera_pv_seg = world.spawn_actor(camera_bp_seg, c_pv_spawn_location)\n",
    "camera_tv = world.spawn_actor(camera_bp, c_tv_spawn_location)\n",
    "\n",
    "\n",
    "# Set up the simulator in synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True \n",
    "settings.fixed_delta_seconds = 0.1\n",
    "world.apply_settings(settings)\n",
    "\n",
    "image_queue_tv = queue.Queue()\n",
    "image_queue_pv = queue.Queue()\n",
    "image_queue_pv_seg = queue.Queue()\n",
    "camera_pv.listen(image_queue_pv.put)\n",
    "camera_pv_seg.listen(image_queue_pv_seg.put)\n",
    "camera_tv.listen(image_queue_tv.put)\n",
    "\n",
    "actors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a3220",
   "metadata": {},
   "source": [
    "## Determine Camera Matrices to calculate World to Camera coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0df3ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_intrinsic_matrix(w, h, fov):\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "    K[0, 0] = K[1, 1] = focal\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K\n",
    "\n",
    "def get_image_point(loc, K, w2c):\n",
    "    # Calculate 2D projection of 3D coordinate\n",
    "\n",
    "    # Format the input coordinate (loc is a carla.Position object)\n",
    "    point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "    # transform to camera coordinates\n",
    "    point_camera = np.dot(w2c, point)\n",
    "\n",
    "    # New we must change from UE4's coordinate system to an \"standard\"\n",
    "    # (x, y ,z) -> (y, -z, x)\n",
    "    # and we remove the fourth componebonent also\n",
    "    point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "\n",
    "    # now project 3D->2D using the camera matrix\n",
    "    point_img = np.dot(K, point_camera)\n",
    "    # normalize\n",
    "    point_img[0] /= point_img[2]\n",
    "    point_img[1] /= point_img[2]\n",
    "\n",
    "    return int(point_img[0]), int(point_img[1])\n",
    "    \n",
    "    \n",
    "# Get the world to camera matrix\n",
    "world_2_camera = np.array(camera_pv.get_transform().get_inverse_matrix())\n",
    "world_2_camera_bev = np.array(camera_tv.get_transform().get_inverse_matrix())\n",
    "\n",
    "# Get the attributes from the camera\n",
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "fov = camera_bp.get_attribute(\"fov\").as_float()\n",
    "\n",
    "# Calculate the camera intrinsic matrix\n",
    "K = build_intrinsic_matrix(image_w, image_h, fov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900048b",
   "metadata": {},
   "source": [
    "## Spawn Actors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a7a70",
   "metadata": {},
   "source": [
    "### Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "770f0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for npc in world.get_actors().filter('*vehicle*'):\n",
    "    npc.destroy()\n",
    "    actors = []\n",
    "    \n",
    "# Spawn Vehicles\n",
    "for i in range(100):\n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle'))\n",
    "    if int(vehicle_bp.get_attribute('number_of_wheels')) != 2:\n",
    "        npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "    if npc:\n",
    "        actors.append(npc)\n",
    "        npc.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f222df",
   "metadata": {},
   "source": [
    "### Peds (currently buggy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53fd6ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' walker_bp = bp_lib.filter(\"walker.pedestrian.*\")\\ncontroller_bp = bp_lib.find(\"controller.ai.walker\")\\n\\nfor npc in world.get_actors().filter(\\'*pedestrian*\\'):\\n    npc.destroy()\\n\\nfor i in range(70):\\n    trans = carla.Transform()\\n    #trans.location = carla.Location(20, 20, 0)\\n    trans.location = world.get_random_location_from_navigation()\\n    trans.location.z += 1\\n    \\n    walker = random.choice(walker_bp)\\n    actor = world.try_spawn_actor(walker, trans)\\n    if actor:\\n        actors.append(actor)\\n    world.tick()\\n    controller = world.try_spawn_actor(controller_bp, carla.Transform(), actor)\\n    controller.start()    \\n    world.tick()\\n    controller.go_to_location(world.get_random_location_from_navigation()) '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" walker_bp = bp_lib.filter(\"walker.pedestrian.*\")\n",
    "controller_bp = bp_lib.find(\"controller.ai.walker\")\n",
    "\n",
    "for npc in world.get_actors().filter('*pedestrian*'):\n",
    "    npc.destroy()\n",
    "\n",
    "for i in range(70):\n",
    "    trans = carla.Transform()\n",
    "    #trans.location = carla.Location(20, 20, 0)\n",
    "    trans.location = world.get_random_location_from_navigation()\n",
    "    trans.location.z += 1\n",
    "    \n",
    "    walker = random.choice(walker_bp)\n",
    "    actor = world.try_spawn_actor(walker, trans)\n",
    "    if actor:\n",
    "        actors.append(actor)\n",
    "    world.tick()\n",
    "    controller = world.try_spawn_actor(controller_bp, carla.Transform(), actor)\n",
    "    controller.start()    \n",
    "    world.tick()\n",
    "    controller.go_to_location(world.get_random_location_from_navigation()) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6a5a8",
   "metadata": {},
   "source": [
    "## Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddee944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_img_bb(bb):\n",
    "    verts = [get_image_point(v, K, world_2_camera) for v in bb.get_world_vertices(npc.get_transform())]\n",
    "    return verts\n",
    "\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]] # For drawing BBOXES\n",
    "\n",
    "dist_cutoff = 90\n",
    "\n",
    "while True:\n",
    "    world.tick()\n",
    "    image_pv = image_queue_pv.get()\n",
    "    image_tv = image_queue_tv.get()\n",
    "    image_pv_seg = image_queue_pv_seg.get()\n",
    "    \n",
    "    # Reshape the raw data into an RGB array\n",
    "    img_pv = np.reshape(np.copy(image_pv.raw_data), (image_pv.height, image_pv.width, 4)) \n",
    "    img_tv = np.reshape(np.copy(image_tv.raw_data), (image_tv.height, image_tv.width, 4)) \n",
    "    img_pv_seg = np.reshape(np.copy(image_pv_seg.raw_data), (image_pv_seg.height, image_pv_seg.width, 4)) \n",
    "    \n",
    "\n",
    "    \n",
    "    #for npc in world.get_actors().filter('*vehicle*').append(world.get_actors().filter('*pedestrian*')):\n",
    "    for npc in actors:\n",
    "        dist = npc.get_transform().location.distance(camera_pv.get_transform().location)\n",
    "        bb = npc.bounding_box\n",
    "        \n",
    "        # Filter for the vehicles within 50m\n",
    "        if dist > dist_cutoff:\n",
    "            continue\n",
    "            \n",
    "        # Calculate the dot product between the forward vector\n",
    "        # of the camera and the vector between the camera\n",
    "        # and the npc. We threshold this dot product\n",
    "        # to limit to drawing bounding boxes IN FRONT OF THE CAMERA\n",
    "        # TODO do this correct...\n",
    "        forward_vec = camera_pv.get_transform().get_forward_vector() \n",
    "        ray = npc.get_transform().location - camera_pv.get_transform().location\n",
    "        angle = math.acos(forward_vec.dot(ray) / (forward_vec.dot(forward_vec) * ray.dot(ray)))\n",
    "        angle = math.degrees(angle)\n",
    "        \n",
    "        if forward_vec.dot(ray) > 1:    \n",
    "            #print(angle) # Weird angle.\n",
    "            #if angle > 45:\n",
    "            #    continue\n",
    "            \n",
    "            # PV\n",
    "            gcp_x, gcp_y = get_image_point(npc.get_location(), K, world_2_camera)\n",
    "        \n",
    "            fvec = npc.get_transform().get_forward_vector()\n",
    "            psi = npc.get_location().x + fvec.x, npc.get_location().y + fvec.y, npc.get_location().z + fvec.z\n",
    "            psi_x, psi_y = get_image_point(carla.Location(psi[0], psi[1], psi[2]), K, world_2_camera)\n",
    "\n",
    "            cv2.circle(img_pv, (gcp_x, gcp_y), 3, (0, 100, 200), -1)\n",
    "            cv2.arrowedLine(img_pv, (gcp_x, gcp_y), (psi_x, psi_y), (255, 0, 0, 255), 2)\n",
    "            \n",
    "            # Bev\n",
    "            gcp_x_bev, gcp_y_bev = get_image_point(npc.get_location(), K, world_2_camera_bev)\n",
    "            psi_x_bev, psi_y_bev = get_image_point(carla.Location(psi[0], psi[1], psi[2]), K, world_2_camera_bev)\n",
    "            cv2.circle(img_tv, (gcp_x_bev, gcp_y_bev), 3, (0, 100, 200), -1)\n",
    "            cv2.arrowedLine(img_tv, (gcp_x_bev, gcp_y_bev), (psi_x_bev, psi_y_bev), (255, 0, 0, 255), 2)\n",
    "  \n",
    "    \n",
    "    # Display the image in an OpenCV display window\n",
    "    cv2.namedWindow('Camera 1', cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('Camera 1', img_pv)\n",
    "    cv2.namedWindow('Camera 1 Seg', cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('Camera 1 Seg', img_pv_seg)\n",
    "    cv2.namedWindow('Top View', cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('Top View', img_tv)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6f5bf",
   "metadata": {},
   "source": [
    "## Make a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590b5e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 82/500 [03:13<16:35,  2.38s/it]"
     ]
    }
   ],
   "source": [
    "## variables for dataset generation\n",
    "dist_cutoff = 50\n",
    "ts = 0\n",
    "iteration = 0\n",
    "max_timesteps = 500\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_img_bb(bb):\n",
    "    verts = [get_image_point(v, K, world_2_camera) for v in bb.get_world_vertices(npc.get_transform())]\n",
    "    return verts\n",
    "\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]] # For drawing BBOXES\n",
    "\n",
    "# Delete Dataset\n",
    "files = glob.glob('output/pv/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "files = glob.glob('output/tv/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "files = glob.glob('output/seg/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "vehicles_pv_per_ts = dict()\n",
    "vehicles_tv_per_ts = dict()\n",
    "\n",
    "\n",
    "pbar = tqdm(total = max_timesteps)\n",
    "while True:\n",
    "    world.tick()\n",
    "    \n",
    "    image_pv = image_queue_pv.get()\n",
    "    image_tv = image_queue_tv.get()\n",
    "    image_pv_seg = image_queue_pv_seg.get()\n",
    "    iteration += 1\n",
    "    \n",
    "    frame_path_pv = 'output/pv/%06d' % image_pv.frame\n",
    "    frame_path_tv = 'output/tv/%06d' % image_tv.frame\n",
    "    frame_path_seg = 'output/seg/%06d' % image_pv_seg.frame\n",
    "    \n",
    "    # Save the image\n",
    "    image_pv.save_to_disk(frame_path_pv + '.png')\n",
    "    image_tv.save_to_disk(frame_path_tv + '.png')\n",
    "    image_pv_seg.save_to_disk(frame_path_seg + '.png', color_converter=carla.ColorConverter.Raw)\n",
    "    \n",
    "      \n",
    "    # Reshape the raw data into an RGB array\n",
    "    img_pv = np.reshape(np.copy(image_pv.raw_data), (image_pv.height, image_pv.width, 4)) \n",
    "    img_tv = np.reshape(np.copy(image_tv.raw_data), (image_tv.height, image_tv.width, 4)) \n",
    "    img_pv_seg = np.reshape(np.copy(image_pv_seg.raw_data), (image_pv_seg.height, image_pv_seg.width, 4)) \n",
    "    \n",
    "    vehicles_pv = []\n",
    "    vehicles_tv = []\n",
    "    \n",
    "    for npc in world.get_actors().filter('*vehicle*'):\n",
    "        dist = npc.get_transform().location.distance(camera_pv.get_transform().location)\n",
    "        bb = npc.bounding_box\n",
    "        \n",
    "        # Filter for the vehicles within\n",
    "        if dist > dist_cutoff:\n",
    "            continue\n",
    "            \n",
    "        # Calculate the dot product between the forward vector\n",
    "        # of the vehicle and the vector between the vehicle\n",
    "        # and the other vehicle. We threshold this dot product\n",
    "        # to limit to drawing bounding boxes IN FRONT OF THE CAMERA\n",
    "        forward_vec = camera_pv.get_transform().get_forward_vector()\n",
    "        ray = npc.get_transform().location - camera_pv.get_transform().location\n",
    "\n",
    "        if forward_vec.dot(ray) > 1:\n",
    "            bb_img = calculate_img_bb(bb)\n",
    "            gcp_x, gcp_y = get_image_point(npc.get_location(), K, world_2_camera)\n",
    "            fvec = npc.get_transform().get_forward_vector()\n",
    "            psi = npc.get_location().x + fvec.x, npc.get_location().y + fvec.y, npc.get_location().z + fvec.z\n",
    "            psi_x, psi_y = get_image_point(carla.Location(psi[0], psi[1], psi[2]), K, world_2_camera)\n",
    "            gcp_x_bev, gcp_y_bev = get_image_point(npc.get_location(), K, world_2_camera_bev)\n",
    "            psi_x_bev, psi_y_bev = get_image_point(carla.Location(psi[0], psi[1], psi[2]), K, world_2_camera_bev)\n",
    "            \n",
    "            entry_pv = {'id': npc.id, 'gcp': [gcp_x, gcp_y], 'psi': [psi_x, psi_y], 'img': frame_path_pv + '.png', 'bb': bb_img}\n",
    "            entry_tv = {'id': npc.id, 'gcp': [gcp_x_bev, gcp_y_bev], 'psi': [psi_x_bev, psi_y_bev], 'img': frame_path_tv + '.png', 'bb': bb_img}\n",
    "            vehicles_pv.append(entry_pv)\n",
    "            vehicles_tv.append(entry_tv)\n",
    "            \n",
    "            #viz\n",
    "            cv2.circle(img_pv, (gcp_x, gcp_y), 3, (0, 100, 200), -1)\n",
    "            cv2.arrowedLine(img_pv, (gcp_x, gcp_y), (psi_x, psi_y), (255, 0, 0, 255), 2)\n",
    "            cv2.circle(img_tv, (gcp_x_bev, gcp_y_bev), 3, (0, 100, 200), -1)\n",
    "            cv2.arrowedLine(img_tv, (gcp_x_bev, gcp_y_bev), (psi_x_bev, psi_y_bev), (255, 0, 0, 255), 2)\n",
    "    #print('iteration', iteration)\n",
    "    pbar.update(1)\n",
    "    vehicles_pv_per_ts[iteration] = vehicles_pv\n",
    "    vehicles_tv_per_ts[iteration] = vehicles_tv\n",
    "    #preview windows\n",
    "    #cv2.namedWindow('Camera 1', cv2.WINDOW_AUTOSIZE)\n",
    "    #cv2.imshow('Camera 1', img_pv)\n",
    "    #cv2.namedWindow('Camera 1 Seg', cv2.WINDOW_AUTOSIZE)\n",
    "    #cv2.imshow('Camera 1 Seg', img_pv_seg)\n",
    "    #cv2.namedWindow('Top View', cv2.WINDOW_AUTOSIZE)\n",
    "    #cv2.imshow('Top View', img_tv)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    if iteration >= max_timesteps:\n",
    "        break\n",
    "\n",
    "##ende\n",
    "pbar.close()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#create pickle dumps\n",
    "\"\"\" with open('output/pv/data.pickle', 'wb') as handle:\n",
    "    pickle.dump(vehicles_pv_per_ts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('output/tv/data.pickle', 'wb') as handle:\n",
    "    pickle.dump(vehicles_tv_per_ts, handle, protocol=pickle.HIGHEST_PROTOCOL) \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62e2d5",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e74cc",
   "metadata": {},
   "source": [
    "### definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1467b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy.typing as npt\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Instance:\n",
    "    id: int  # vehicle id from carla\n",
    "    ts: int  # timestamp should also be the image name in seg, pv and tv folders\n",
    "    # pv\n",
    "    gcp_pv: npt.NDArray[np.int_]  # [2,] Ground contact point\n",
    "    psi_pv: npt.NDArray[np.int_]  # [2,] point for the direction of the vehicle\n",
    "    bb_pv: npt.NDArray[np.int_]   # [8, 2] # 3d bounding box of the vehicle\n",
    "    hull_pv: npt.NDArray[np.int_]  # [n, 2] # hull of the vehicle\n",
    "    image_pv: str        # path to the image\n",
    "    # tv\n",
    "    gcp_tv: npt.NDArray[np.int_]  # [2,] Ground contact point\n",
    "    psi_tv: npt.NDArray[np.int_]  # [2,] point for the direction of the vehicle\n",
    "    bb_tv: npt.NDArray[np.int_]   # [8, 2] # 3d bounding box of the vehicle\n",
    "    image_tv: str        # path to the image\n",
    "\n",
    "street_colors = []\n",
    "\n",
    "def is_vehicle_out_of_bounds(gcp, w=1920, h=1080):\n",
    "    x, y = gcp\n",
    "    if x > w or x < 0 or y > h or y < 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_vehicles_from_ts(data, ts):\n",
    "    return data[ts]\n",
    "\n",
    "def get_vehicles_from_random_ts(data):\n",
    "    idx_ts = random.choice(list(data.keys()))\n",
    "    return idx_ts, data[idx_ts]\n",
    "\n",
    "def filter_vehicles_not_in_img(data, w=1920, h=1080):\n",
    "    return [vehicle for vehicle in data if not is_vehicle_out_of_bounds(vehicle['gcp'], w, h)]\n",
    "\n",
    "def get_random_vehicle(data):\n",
    "    idx = random.randint(0, len(data)-1)\n",
    "    return data[idx]\n",
    "\n",
    "def get_vehicles_from_ts(data, ts):\n",
    "    return data[ts]\n",
    "\n",
    "def get_vehicle_ids(data):\n",
    "    return [vehicle['id'] for vehicle in data]\n",
    "\n",
    "def filter_tv_vehicles(data, vehicle_ids):\n",
    "    return [vehicle for vehicle in data if vehicle['id'] in vehicle_ids]\n",
    "\n",
    "def cut_mask(bb, image):\n",
    "    bb2d = bb_to_2d(np.array(bb))\n",
    "    xmin, ymin, xmax, ymax = bb2d\n",
    "    image_cropped = np.asarray(image)[ymin:ymax, xmin:xmax]\n",
    "    return image_cropped\n",
    "\n",
    "def get_mask(bb, image_cropped, image_seg):\n",
    "    rgba, counts = np.unique(image_cropped.reshape(-1,4), axis=0, return_counts=True)\n",
    "    # Filter street ((1, 51, 115, 255) inters2)\n",
    "    mask = ~np.all((rgba == np.array([1, 94, 110, 255])), axis=1)\n",
    "\n",
    "    rgba = rgba[mask]\n",
    "    counts = counts[mask]\n",
    "    target_value = rgba[np.argmax(counts)]\n",
    "    mask = np.all(np.asarray(image_seg) == target_value, axis=-1)\n",
    "    id = target_value[0]\n",
    "    if (id == 1 or id == 2 or id == 3 or id == 9):\n",
    "        street_colors.append(target_value)\n",
    "    return mask\n",
    "\n",
    "def get_hull(mask):\n",
    "    object_pixels = np.column_stack(np.where(mask))\n",
    "    hull = cv2.convexHull(object_pixels)\n",
    "    hull = hull.squeeze()\n",
    "    return hull\n",
    "\n",
    "def bb_to_2d(bb):\n",
    "    x_min, x_max = np.min(bb[:, 0]), np.max(bb[:, 0])\n",
    "    y_min, y_max = np.min(bb[:, 1]), np.max(bb[:, 1])\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def plot_2d_box(bb):\n",
    "    x_min, y_min, x_max, y_max = bb_to_2d(bb)\n",
    "    plt.plot([x_min, x_min], [y_min, y_max], color='red')\n",
    "    plt.plot([x_max, x_max], [y_min, y_max], color='red')\n",
    "    plt.plot([x_min, x_max], [y_min, y_min], color='red')\n",
    "    plt.plot([x_min, x_max], [y_max, y_max], color='red')\n",
    "\n",
    "def plot_3d_box(bb):\n",
    "    edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "    for edge in edges:\n",
    "        plt.plot(bb[edge, 0], bb[edge, 1], color='blue')\n",
    "\n",
    "def plot_gcp(gcp):\n",
    "    _ = plt.scatter(gcp[0], gcp[1], color='cyan', marker='*', s=30)\n",
    "\n",
    "def plot_psi(gcp, psi):\n",
    "    x, y = gcp\n",
    "    x2, y2 = psi\n",
    "    _ = plt.plot([x, x2], [y, y2], color='red', lw=2)\n",
    "\n",
    "def plot_hull(hull):\n",
    "    hull = np.vstack((hull, hull[0, :]))\n",
    "    plt.plot(hull[:, 1], hull[:, 0], color='orange')\n",
    "\n",
    "\n",
    "def append_min_area_rect(data):\n",
    "    for vehicle in data:\n",
    "        min_area_rect = cv2.minAreaRect(vehicle['hull']) # Maybe need rotation\n",
    "        box = cv2.boxPoints(min_area_rect)\n",
    "        box = np.intp(box)\n",
    "        vehicle['min_area_rect'] = box\n",
    "    return data\n",
    "\n",
    "def plot_min_area_rect(box):\n",
    "    box = np.vstack((box, box[0, :]))\n",
    "    plt.plot(box[:, 1], box[:, 0], color='cyan')\n",
    "\n",
    "def get_data(ts, base_url='./', w=1980, h=1080):\n",
    "    # Load Pickle Data\n",
    "    with open(base_url + 'output/pv/data.pickle', 'rb') as handle:\n",
    "        data_pv = pickle.load(handle)\n",
    "\n",
    "    with open(base_url + 'output/tv/data.pickle', 'rb') as handle:\n",
    "        data_tv = pickle.load(handle)\n",
    "        \n",
    "    # Perspective View\n",
    "    vehicles_at_ts = get_vehicles_from_ts(data_pv, ts)\n",
    "    vehicles_at_ts_filtered = filter_vehicles_not_in_img(vehicles_at_ts, w, h)\n",
    "    vehicles_pv = append_hull(base_url, vehicles_at_ts_filtered)\n",
    "    vehicles_pv = append_min_area_rect(vehicles_at_ts_filtered)\n",
    "    fname_pv = base_url + vehicles_at_ts_filtered[0]['img']\n",
    "    \n",
    "    # Top View\n",
    "    vehicles_at_ts_tv = get_vehicles_from_ts(data_tv, ts)\n",
    "    v_ids = get_vehicle_ids(vehicles_pv)\n",
    "    vehicles_tv = filter_tv_vehicles(vehicles_at_ts_tv, v_ids)\n",
    "    fname_tv = base_url+vehicles_tv[0]['img']\n",
    "\n",
    "def clean_segmask(image_seg):\n",
    "    \"\"\" Removes all non-car pixels from the segmentation mask.\n",
    "    Supposed to be called once per segmentation mask.\n",
    "    Args:\n",
    "    image_seg (_type_): Segmentation mask opened with opencv in rgba format\n",
    "    Returns:\n",
    "    _type_: Mask with only car pixels\n",
    "    \"\"\"\n",
    "    cars_min = np.array([0, 0, 13, 0])\n",
    "    cars_max = np.array([255, 255, 15, 255])\n",
    "    mask = cv2.inRange(image_seg, cars_min, cars_max)\n",
    "    return mask\n",
    " \n",
    " \n",
    "def cut_mask(bb, cleaned_mask):\n",
    "    \"\"\"Sets all pixels outside of the bounding box to 0.\n",
    "    Args:\n",
    "        bb (_type_): bounding box of the current vehicle\n",
    "        cleaned_mask (_type_): Mask with all other colors expcept vehicles removed\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    bb2d = bb_to_2d(np.array(bb))\n",
    "    xmin, ymin, xmax, ymax = bb2d\n",
    "    to_ignore = np.ones(cleaned_mask.shape[:2], dtype=bool)\n",
    "    to_ignore[ymin:ymax, xmin:xmax] = False\n",
    "    cleaned_mask = cleaned_mask.copy()\n",
    "    cleaned_mask[to_ignore] = 0\n",
    "    return cleaned_mask\n",
    "\n",
    "def append_hull(base_url, data):\n",
    "    fname = base_url+data[0]['img']\n",
    "    fname_seg = base_url + 'output/seg/' + fname.split('/')[-1]\n",
    "    image_seg = cv2.imread(fname_seg, cv2.IMREAD_UNCHANGED)\n",
    "    image_seg = clean_segmask(image_seg)\n",
    "    for vehicle in data:\n",
    "        mask = cut_mask(vehicle['bb'], image_seg)\n",
    "        hull = get_hull(mask)\n",
    "\n",
    "\n",
    "        vehicle['hull'] = hull\n",
    "    return data\n",
    "\n",
    "def calculate_hull(seg_mask, bounding_box):\n",
    "    mask = cut_mask(bounding_box, seg_mask)\n",
    "    return get_hull(mask)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce9d80",
   "metadata": {},
   "source": [
    "### execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "346251ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 19 instances to pickle\n"
     ]
    }
   ],
   "source": [
    "base_url = './'\n",
    "w = 1980\n",
    "h = 1080\n",
    "\n",
    "all_instances = []\n",
    "\n",
    "for i in vehicles_pv_per_ts.keys():\n",
    "    data_pv = vehicles_pv_per_ts[i]\n",
    "    data_tv = vehicles_tv_per_ts[i]\n",
    "    vehicles_pv = filter_vehicles_not_in_img(data_pv, w, h)\n",
    "    #vehicles_pv = append_hull(base_url, vehicles_at_ts_filtered)\n",
    "    #vehicles_pv = append_min_area_rect(vehicles_at_ts_filtered)\n",
    "    fname_pv = base_url + vehicles_at_ts_filtered[0]['img']\n",
    "    #image_pv = Image.open(fname_pv)\n",
    "    \n",
    "    # Top View\n",
    "    vehicles_at_ts_tv = get_vehicles_from_ts(data_tv, ts)\n",
    "    v_ids = get_vehicle_ids(vehicles_pv)\n",
    "    vehicles_tv = filter_tv_vehicles(data_tv, v_ids)\n",
    "    list[tuple[float, float]]\n",
    "    fname_tv = base_url+vehicles_tv[0]['img']\n",
    "    assert len(vehicles_pv) == len(vehicles_tv)\n",
    "\n",
    "    fname = base_url+data_pv[0]['img']\n",
    "    fname_seg = base_url + 'output/seg/' + fname.split('/')[-1]\n",
    "    image_seg = cv2.imread(fname_seg, cv2.IMREAD_UNCHANGED)\n",
    "    image_seg = clean_segmask(image_seg)\n",
    "\n",
    "    for vehicle_pv, vehicle_tv in zip(vehicles_pv, vehicles_tv):\n",
    "\n",
    "        try:\n",
    "            hull = calculate_hull(image_seg, vehicle_pv[\"bb\"])\n",
    "        except:\n",
    "            continue # skip all vehicles where the hull cant be calculated\n",
    "           \n",
    "        instance = Instance(vehicle_pv['id'], \n",
    "                            i,\n",
    "                            np.array(vehicle_pv['gcp']),\n",
    "                            np.array(vehicle_pv['psi']),\n",
    "                            np.array(vehicle_pv['bb']),\n",
    "                            np.array(np.array(hull)),\n",
    "                            vehicle_pv['img'] ,\n",
    "                            np.array(vehicle_tv['gcp']),\n",
    "                            np.array(vehicle_tv['psi']),\n",
    "                            np.array(vehicle_tv['bb']),\n",
    "                            vehicle_tv['img']\n",
    "                            )\n",
    "        all_instances.append(instance)\n",
    "\n",
    "with open('output/instances.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_instances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved {len(all_instances)} instances to pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
