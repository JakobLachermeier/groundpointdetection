{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63c3b0a",
   "metadata": {},
   "source": [
    "# Dynamic Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do:\n",
    "- automate intersection camera location workflow with pickle and dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d48b0f",
   "metadata": {},
   "source": [
    "## Setup Sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb4cf0",
   "metadata": {},
   "source": [
    "### setup modules, import functions and module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a311d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30618"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import queue\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import *\n",
    "\n",
    "client = carla.Client('localhost', 2000)\n",
    "world  = client.get_world()\n",
    "bp_lib = world.get_blueprint_library()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "spectator = world.get_spectator() \n",
    "\n",
    "#load list for camera points\n",
    "cam_perspectives = {}\n",
    "try:\n",
    "    with open('./cam_perspectives.pickle', 'rb') as handle:\n",
    "        fresh_opened_jar_of_pickles = pickle.load(handle)\n",
    "except:\n",
    "    print(\"careful: no pickle was loaded with previously saved intersections\")\n",
    "\n",
    "#return pickled lists to carla transform objects\n",
    "for key, fresh_pickle in fresh_opened_jar_of_pickles.items():\n",
    "    cam_perspectives[key] = unpickle_to_carla(fresh_pickle)\n",
    "\n",
    "##wipe intermediary lists clean\n",
    "fresh_opened_jar_of_pickles = {}\n",
    "\n",
    "# Set up the simulator in synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True\n",
    "#time step used throughout\n",
    "ticktime = 0.10 #max 0.10\n",
    "settings.fixed_delta_seconds = ticktime\n",
    "settings.max_substep_delta_time = ticktime/10 #max 0.01 \n",
    "world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter1tv\n",
      "inter1pv1\n",
      "inter1pv2\n",
      "inter1pv3\n",
      "inter1pv4\n",
      "inter1pv5\n",
      "inter1pv6\n",
      "inter2tv\n",
      "inter2pv1\n",
      "inter2pv2\n",
      "inter2pv3\n",
      "inter2pv4\n"
     ]
    }
   ],
   "source": [
    "for key in cam_perspectives:\n",
    "  print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastzip: 15\n"
     ]
    }
   ],
   "source": [
    "print(f'lastzip: {lastzipnmbr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor(id=1915, type=sensor.camera.instance_segmentation)\n",
      "Actor(id=1914, type=sensor.camera.rgb)\n",
      "Actor(id=1916, type=sensor.camera.rgb)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for sensor in world.get_actors().filter('*sensor*'):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bf5936",
   "metadata": {},
   "source": [
    "### Set Variables for Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8f6119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastzipnmbr = 69\n",
    "intersection = 'inter2'\n",
    "perspectives = 1\n",
    "\n",
    "tv_key = intersection + 'tv'\n",
    "\n",
    "## variables for dataset generation\n",
    "dist_cutoff = 90\n",
    "ts = 0\n",
    "iteration = 0\n",
    "max_timesteps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed17a6ce",
   "metadata": {},
   "source": [
    "### Execute in Bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "792dcbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter2pv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished generating inter2pv1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 20 instances to pickle for inter2pv1\n",
      "set82_inter2pv1\n"
     ]
    }
   ],
   "source": [
    "for i in range(perspectives):\n",
    "    pv_key = intersection + 'pv' + str(i+1)\n",
    "    print(pv_key)\n",
    "    iteration = 0\n",
    "    ts = 0\n",
    "\n",
    "    ## set view\n",
    "    c_pv_spawn_location = cam_perspectives[pv_key]\n",
    "    c_tv_spawn_location = cam_perspectives[tv_key]\n",
    "\n",
    "    spectator.set_transform(c_tv_spawn_location) \n",
    "\n",
    "    # Determine Camera Parameters\n",
    "    camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', '1920')\n",
    "    camera_bp.set_attribute('image_size_y', '1080')\n",
    "\n",
    "    camera_bp_seg = bp_lib.find('sensor.camera.instance_segmentation')\n",
    "    camera_bp_seg.set_attribute('image_size_x', '1920')\n",
    "    camera_bp_seg.set_attribute('image_size_y', '1080')\n",
    "\n",
    "    ############################################################\n",
    "    ## Spawn Actors\n",
    "    ############################################################\n",
    "    ## Vehicles\n",
    "    ## note: spawn vehicles before starting cameras to give them time to exist\n",
    "    for npc in world.get_actors().filter('*vehicle*'):\n",
    "        npc.destroy()\n",
    "        actors = []\n",
    "    # Spawn Vehicles (excluding 2 wheeled)\n",
    "    for i in range(150):\n",
    "        vehicle_bp = random.choice(bp_lib.filter('vehicle'))\n",
    "        if int(vehicle_bp.get_attribute('number_of_wheels')) != 2:\n",
    "            npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "        if npc:\n",
    "            actors.append(npc)\n",
    "            npc.set_autopilot(True)\n",
    "    #let it finish spawning\n",
    "    for i in range(20):\n",
    "        world.tick()\n",
    "\n",
    "    #############################################################\n",
    "    ## Sensors\n",
    "    # Create a queue to store and retrieve the sensor data\n",
    "    # clean up old sensors first\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        world.tick()       \n",
    "        sensor.destroy()\n",
    "    #spawn new sensors\n",
    "    camera_pv = world.spawn_actor(camera_bp, c_pv_spawn_location)\n",
    "    camera_pv_seg = world.spawn_actor(camera_bp_seg, c_pv_spawn_location)\n",
    "    camera_tv = world.spawn_actor(camera_bp, c_tv_spawn_location)\n",
    "    ##############################################################\n",
    "    ## from here every world.tick() is a frame, do not desync the frame from the timestep\n",
    "    ##############################################################\n",
    "    #create queue\n",
    "    image_queue_tv = queue.Queue()\n",
    "    image_queue_pv = queue.Queue()\n",
    "    image_queue_pv_seg = queue.Queue()\n",
    "    camera_pv.listen(image_queue_pv.put)\n",
    "    camera_pv_seg.listen(image_queue_pv_seg.put)\n",
    "    camera_tv.listen(image_queue_tv.put)\n",
    "\n",
    "    actors = []\n",
    "\n",
    "    ## Determine Camera Matrices to calculate World to Camera coordinates\n",
    "    def build_intrinsic_matrix(w, h, fov):\n",
    "        focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "        K = np.identity(3)\n",
    "        K[0, 0] = K[1, 1] = focal\n",
    "        K[0, 2] = w / 2.0\n",
    "        K[1, 2] = h / 2.0\n",
    "        return K\n",
    "    \n",
    "    def get_image_point(loc, K, w2c):\n",
    "        # Calculate 2D projection of 3D coordinate\n",
    "\n",
    "        # Format the input coordinate (loc is a carla.Position object)\n",
    "        point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "        # transform to camera coordinates\n",
    "        point_camera = np.dot(w2c, point)\n",
    "\n",
    "        # New we must change from UE4's coordinate system to an \"standard\"\n",
    "        # (x, y ,z) -> (y, -z, x)\n",
    "        # and we remove the fourth componebonent also\n",
    "        point_camera = [point_camera[1], -point_camera[2], point_camera[0]]\n",
    "\n",
    "        # now project 3D->2D using the camera matrix\n",
    "        point_img = np.dot(K, point_camera)\n",
    "        # normalize\n",
    "        point_img[0] /= point_img[2]\n",
    "        point_img[1] /= point_img[2]\n",
    "\n",
    "        return int(point_img[0]), int(point_img[1])\n",
    "        \n",
    "        \n",
    "    # Get the world to camera matrix\n",
    "    world_2_camera = np.array(camera_pv.get_transform().get_inverse_matrix())\n",
    "    world_2_camera_bev = np.array(camera_tv.get_transform().get_inverse_matrix())\n",
    "\n",
    "    # Get the attributes from the camera\n",
    "    image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "    image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "    fov = camera_bp.get_attribute(\"fov\").as_float()\n",
    "\n",
    "    # Calculate the camera intrinsic matrix\n",
    "    K = build_intrinsic_matrix(image_w, image_h, fov)\n",
    "      \n",
    "\n",
    "    ########################################## \n",
    "    ## make dataset\n",
    "    ##########################################\n",
    "\n",
    "    import pickle\n",
    "    import os\n",
    "    import glob\n",
    "    from tqdm import tqdm\n",
    "    %autoreload 2\n",
    "\n",
    "    def calculate_img_bb(bb):\n",
    "        verts = [get_image_point(v, K, world_2_camera) for v in bb.get_world_vertices(npc.get_transform())]\n",
    "        return verts\n",
    "\n",
    "    def get_mask(bb, image_cropped, image_seg):\n",
    "        rgba, counts = np.unique(image_cropped.reshape(-1,4), axis=0, return_counts=True)\n",
    "        # Filter street ((1, 51, 115, 255) inters2)\n",
    "        mask = ~np.all((rgba == np.array([1, 94, 110, 255])), axis=1)\n",
    "\n",
    "        rgba = rgba[mask]\n",
    "        counts = counts[mask]\n",
    "        target_value = rgba[np.argmax(counts)]\n",
    "        mask = np.all(np.asarray(image_seg) == target_value, axis=-1)\n",
    "        id = target_value[0]\n",
    "        if (id == 1 or id == 2 or id == 3 or id == 9):\n",
    "            street_colors.append(target_value)\n",
    "        return mask\n",
    "\n",
    "    edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]] # For drawing BBOXES\n",
    "\n",
    "    # Delete Dataset\n",
    "    files = glob.glob('output/pv/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    files = glob.glob('output/tv/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    files = glob.glob('output/seg/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "    vehicles_pv_per_ts = dict()\n",
    "    vehicles_tv_per_ts = dict()\n",
    "\n",
    "    ########################################\n",
    "    ## loop to generate frames and info\n",
    "    ########################################\n",
    "    pbar = tqdm(total = max_timesteps)  #progress bar wrapped around\n",
    "    while True:\n",
    "        world.tick()\n",
    "        \n",
    "        image_pv = image_queue_pv.get()\n",
    "        image_tv = image_queue_tv.get()\n",
    "        image_pv_seg = image_queue_pv_seg.get()\n",
    "        iteration += 1\n",
    "        \n",
    "        frame_path_pv = 'output/pv/%06d' % image_pv.frame\n",
    "        frame_path_tv = 'output/tv/%06d' % image_tv.frame\n",
    "        frame_path_seg = 'output/seg/%06d' % image_pv_seg.frame\n",
    "        \n",
    "        # Save the image\n",
    "        image_pv.save_to_disk(frame_path_pv + '.png')\n",
    "        image_tv.save_to_disk(frame_path_tv + '.png')\n",
    "        image_pv_seg.save_to_disk(frame_path_seg + '.png', color_converter=carla.ColorConverter.Raw)\n",
    "        \n",
    "        \n",
    "        # Reshape the raw data into an RGB array\n",
    "        img_pv = np.reshape(np.copy(image_pv.raw_data), (image_pv.height, image_pv.width, 4)) \n",
    "        img_tv = np.reshape(np.copy(image_tv.raw_data), (image_tv.height, image_tv.width, 4)) \n",
    "        img_pv_seg = np.reshape(np.copy(image_pv_seg.raw_data), (image_pv_seg.height, image_pv_seg.width, 4)) \n",
    "        \n",
    "        vehicles_pv = []\n",
    "        vehicles_tv = []\n",
    "        \n",
    "        for npc in world.get_actors().filter('*vehicle*'):\n",
    "            dist = npc.get_transform().location.distance(camera_pv.get_transform().location)\n",
    "            bb = npc.bounding_box\n",
    "            \n",
    "            # Filter for the vehicles within\n",
    "            if dist > dist_cutoff:\n",
    "                continue\n",
    "                \n",
    "            # Calculate the dot product between the forward vector\n",
    "            # of the vehicle and the vector between the vehicle\n",
    "            # and the other vehicle. We threshold this dot product\n",
    "            # to limit to drawing bounding boxes IN FRONT OF THE CAMERA\n",
    "            forward_vec = camera_pv.get_transform().get_forward_vector()\n",
    "            ray = npc.get_transform().location - camera_pv.get_transform().location\n",
    "\n",
    "            if forward_vec.dot(ray) > 1:\n",
    "                bb_img = calculate_img_bb(bb)\n",
    "                gcp_x, gcp_y = get_image_point(npc.get_location(), K, world_2_camera)\n",
    "                fvec = npc.get_transform().get_forward_vector()\n",
    "                psi = npc.get_location().x + fvec.x, npc.get_location().y + fvec.y, npc.get_location().z + fvec.z\n",
    "                psi_x, psi_y = get_image_point(carla.Location(psi[0], psi[1], psi[2]), K, world_2_camera)\n",
    "                gcp_x_bev, gcp_y_bev = get_image_point(npc.get_location(), K, world_2_camera_bev)\n",
    "                psi_x_bev, psi_y_bev = get_image_point(carla.Location(psi[0], psi[1], psi[2]), K, world_2_camera_bev)\n",
    "                \n",
    "                entry_pv = {'id': npc.id, 'gcp': [gcp_x, gcp_y], 'psi': [psi_x, psi_y], 'img': frame_path_pv + '.png', 'bb': bb_img}\n",
    "                entry_tv = {'id': npc.id, 'gcp': [gcp_x_bev, gcp_y_bev], 'psi': [psi_x_bev, psi_y_bev], 'img': frame_path_tv + '.png', 'bb': bb_img}\n",
    "                vehicles_pv.append(entry_pv)\n",
    "                vehicles_tv.append(entry_tv)\n",
    "                \n",
    "        #print('iteration', iteration)\n",
    "        pbar.update(1)\n",
    "        vehicles_pv_per_ts[iteration] = vehicles_pv\n",
    "        vehicles_tv_per_ts[iteration] = vehicles_tv\n",
    "\n",
    "\n",
    "        if iteration >= max_timesteps:\n",
    "            break\n",
    "\n",
    "    ##ende\n",
    "    pbar.close()\n",
    "    print(f'finished generating {pv_key}')\n",
    "    ####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    ## Package\n",
    "    ######################################\n",
    "    import random \n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    import cv2\n",
    "    import numpy.typing as npt\n",
    "    from dataclasses import dataclass\n",
    "    %autoreload 2\n",
    "\n",
    "    @dataclass(frozen=True)\n",
    "    class Instance:\n",
    "        id: int  # vehicle id from carla\n",
    "        ts: int  # timestamp should also be the image name in seg, pv and tv folders\n",
    "        # pv\n",
    "        gcp_pv: npt.NDArray[np.int_]  # [2,] Ground contact point\n",
    "        psi_pv: npt.NDArray[np.int_]  # [2,] point for the direction of the vehicle\n",
    "        bb_pv: npt.NDArray[np.int_]   # [8, 2] # 3d bounding box of the vehicle\n",
    "        hull_pv: npt.NDArray[np.int_]  # [n, 2] # hull of the vehicle\n",
    "        image_pv: str        # path to the image\n",
    "        # tv\n",
    "        gcp_tv: npt.NDArray[np.int_]  # [2,] Ground contact point\n",
    "        psi_tv: npt.NDArray[np.int_]  # [2,] point for the direction of the vehicle\n",
    "        bb_tv: npt.NDArray[np.int_]   # [8, 2] # 3d bounding box of the vehicle\n",
    "        image_tv: str        # path to the image\n",
    "\n",
    "    street_colors = []\n",
    "\n",
    "    base_url = './'\n",
    "    w = 1980\n",
    "    h = 1080\n",
    "\n",
    "    all_instances = []\n",
    "\n",
    "    pbar = tqdm(total = len(vehicles_pv_per_ts.keys()))          #progress bar\n",
    "    for i in vehicles_pv_per_ts.keys():\n",
    "        pbar.update(1)\n",
    "        data_pv = vehicles_pv_per_ts[i]\n",
    "        data_tv = vehicles_tv_per_ts[i]\n",
    "        vehicles_pv = filter_vehicles_not_in_img(data_pv, w, h)\n",
    "        #vehicles_pv = append_hull(base_url, vehicles_at_ts_filtered)\n",
    "        #vehicles_pv = append_min_area_rect(vehicles_at_ts_filtered)\n",
    "        fname_pv = base_url + data_pv[0]['img']             # was vehicles_at_ts_filtered\n",
    "        #image_pv = Image.open(fname_pv)\n",
    "        \n",
    "        # Top View\n",
    "        vehicles_at_ts_tv = get_vehicles_from_ts(data_tv, ts)\n",
    "        v_ids = get_vehicle_ids(vehicles_pv)\n",
    "        vehicles_tv = filter_tv_vehicles(data_tv, v_ids)\n",
    "        if len(vehicles_tv) == 0:       # skip if no valid vehicles in frame\n",
    "            continue\n",
    "        fname_tv = base_url+vehicles_tv[0]['img']\n",
    "        assert len(vehicles_pv) == len(vehicles_tv)\n",
    "\n",
    "        fname = base_url+data_pv[0]['img']\n",
    "        fname_seg = base_url + 'output/seg/' + fname.split('/')[-1]\n",
    "        image_seg = cv2.imread(fname_seg, cv2.IMREAD_UNCHANGED)\n",
    "        image_seg = clean_segmask(image_seg)\n",
    "\n",
    "        for vehicle_pv, vehicle_tv in zip(vehicles_pv, vehicles_tv):\n",
    "\n",
    "            hull = calculate_hull(image_seg, vehicle_pv[\"bb\"])\n",
    "            if hull is None: # skip all vehicles where the hull cant be calculated\n",
    "                continue\n",
    "            instance = Instance(vehicle_pv['id'], \n",
    "                                i,\n",
    "                                np.array(vehicle_pv['gcp']),\n",
    "                                np.array(vehicle_pv['psi']),\n",
    "                                np.array(vehicle_pv['bb']),\n",
    "                                np.array(np.array(hull)),\n",
    "                                vehicle_pv['img'] ,\n",
    "                                np.array(vehicle_tv['gcp']),\n",
    "                                np.array(vehicle_tv['psi']),\n",
    "                                np.array(vehicle_tv['bb']),\n",
    "                                vehicle_tv['img']\n",
    "                                )\n",
    "            all_instances.append(instance)\n",
    "            \n",
    "    pbar.close()\n",
    "\n",
    "    with open('output/instances.pickle', 'wb') as handle:\n",
    "        pickle.dump(all_instances, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Saved {len(all_instances)} instances to pickle for {pv_key}\")\n",
    "\n",
    "    #####################\n",
    "    # zip it up\n",
    "    #####################\n",
    "    import shutil\n",
    "\n",
    "    lastzipnmbr += 1\n",
    "    zipfilename = \"set\" + str(lastzipnmbr) + '_' + pv_key\n",
    "\n",
    "    print(zipfilename)\n",
    "\n",
    "    shutil.make_archive(zipfilename, format='zip', root_dir='output')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f222df",
   "metadata": {},
   "source": [
    "### Peds (currently buggy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" walker_bp = bp_lib.filter(\"walker.pedestrian.*\")\n",
    "controller_bp = bp_lib.find(\"controller.ai.walker\")\n",
    "\n",
    "for npc in world.get_actors().filter('*pedestrian*'):\n",
    "    npc.destroy()\n",
    "\n",
    "for i in range(70):\n",
    "    trans = carla.Transform()\n",
    "    #trans.location = carla.Location(20, 20, 0)\n",
    "    trans.location = world.get_random_location_from_navigation()\n",
    "    trans.location.z += 1\n",
    "    \n",
    "    walker = random.choice(walker_bp)\n",
    "    actor = world.try_spawn_actor(walker, trans)\n",
    "    if actor:\n",
    "        actors.append(actor)\n",
    "    world.tick()\n",
    "    controller = world.try_spawn_actor(controller_bp, carla.Transform(), actor)\n",
    "    controller.start()    \n",
    "    world.tick()\n",
    "    controller.go_to_location(world.get_random_location_from_navigation()) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
